## 1.synchronized 原理，怎么保证可重入性，可见性，抛异常怎么办，和 lock 锁的区别，2 个线程同时访问一个 synchronized 静态方法和非静态方法，分别怎么进行
synchronized的三种应用方式：  
　　synchronized有三种方式来加锁，分别是：方法锁，对象锁synchronized(this)，类锁synchronized(Demo.Class)。
其中在方法锁层面可以有如下3种方式：  
1.修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁  
2.静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁  
3.修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。  

Java对象头：在Hotspot虚拟机中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充；Java对象头是实现synchronized的锁对象的基础，一般而言，synchronized使用的锁对象是存储在Java对象头里。它是轻量级锁和偏向锁的关键  

synchronized可重入锁的实现：每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。  

synchronized的两条规定：  
1）线程解锁前，必须把共享变量的最新值刷新到主内存中  
2）线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新获取最新的值（注意：加锁与解锁需要是同一把锁）  
通过以上两点，可以看到synchronized能够实现可见性。同时，由于synchronized具有同步锁，所以它也具有原子性  

抛异常怎么办：当一个线程执行的代码出现异常时，其所持有的锁会自动释放

synchronized与Lock的区别:  
1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；  
2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；  
3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；  
4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；  
5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可中断、可公平（两者皆可）  
6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。  
  
## 2. volatile 作用，原理，怎么保证可见性的，内存屏障
作用：保证 可见性、有序性  
原理：
1）#lock前缀指令、MESI缓存一致性协议
对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU,CPU在计算完成后会立即将这个值写回主内存，同时因为有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改。
如果发现别人修改了某个缓存的数据，那么CPU会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取那个变量的时候，就会从主内存中重新加载最新的数据。  
（2）内存屏障：禁止指令重排  
屏障类别：  
每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排  
每个volatile写操作后面，加StoreLoad屏障，禁止和下面的volatile读、写重排  
每个volatile读操作前面，加LoadLoad屏障，禁止上面的普通读和volatile读重排  
每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排  

## 3. 你了解哪些锁，乐观锁和悲观锁，为什么读要加锁，乐观锁为什么适合读场景，写场景不行么，会有什么问题，cas 原理
悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁；Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。  
乐观锁：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。  
为什么读要加锁：任何锁表面上是互斥，但本质是都是为了避免原子性问题（如果程序没有原子性问题，那只用volatile来避免可见性和有序性问题就可以了，效率更高），读锁自然也是为了避免原子性问题，比如一个long型参数的写操作并不是原子性的，如果允许同时读和写，那读到的数很可能是就是写操作的中间状态，比如刚写完前32位的中间状态。long型数都如此，而实际上一般读的都是复杂的对象，那中间状态的情况就更多了。  

cas原理：  
1.java 的 cas 利用的的是 unsafe 这个类提供的 cas 操作。  
2.unsafe 的cas 依赖了的是 jvm 针对不同的操作系统实现的 Atomic::cmpxchg  
3.Atomic::cmpxchg 的实现使用了汇编的 cas 操作，并使用 cpu 硬件提供的 lock信号保证其原子性  

## 4. 什么情况下产生死锁，怎么排查，怎么解决
死锁排查：执行jps命令，得到运行的线程的id，再执行jstack命令，查看结果。

## 5. 一致性 hash 原理，解决什么问题，数据倾斜，为什么是 2 的 32 次方，20 次方可以么

## 6. redis 缓存穿透，布隆过滤器，怎么使用，有什么问题，怎么解决这个问题
缓存穿透：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。  
解决：第一种是缓存层缓存空值，第二种是布隆过滤器
缓存击穿：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。  
缓存雪崩：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。  

布隆过滤器原理：  
原理就是一个对一个key进行k个hash算法获取k个值，在比特数组中将这k个值散列后设定为1，然后查的时候如果特定的这几个位置都为1，那么布隆过滤器判断该key存在。  
布隆过滤器可能会误判，如果它说不存在那肯定不存在，如果它说存在，那数据有可能实际不存在；  
Redis的bitmap只支持2^32大小，对应到内存也就是512MB，误判率万分之一，可以放下2亿左右的数据，性能高，空间占用率及小，省去了大量无效的数据库连接。  
因此我们可以通过布隆过滤器，将Redis缓存穿透控制在一个可容范围内。  

## 7. redis 分布式锁，过期时间怎么定的，如果一个业务执行时间比较长，锁过期了怎么办，怎么保证释放锁的一个原子性，你们 redis 是集群的么，讲讲 redlock 算法
分布式锁过期解决：1.任务执行的时候，开辟一个守护线程，在守护线程中每隔一段时间重新设置过期时间；2.思路二：通过Redisson中的看门狗来实现。

## 8. mysql 事务，acid，实现原理，脏读，脏写，隔离级别，实现原理，mvcc，幻读，间隙锁原理，什么情况下会使用间隙锁，锁失效怎么办，其他锁了解么，行锁，表锁

## 9. mysql 索引左前缀原理，怎么优化，哪些字段适合建索引，索引有什么优缺点
最左前缀原理优化：1.经常会被使用到的列优先；2.选择性高的列优先；3.宽度小的列优先  

## 10. 线上遇到过慢查询么，怎么定位，优化的，explain，using filesort 表示什么意思，产生原因，怎么解决

## 11. 怎么理解幂等性，有遇到过实际场景么，怎么解决的，为什么用 redis，redis 过期了或者数据没了怎么办
一次和多次请求某一个资源对于资源本身应该具有同样的结果  
解决方案：  
1.数据库唯一主键；  
2.数据库乐观锁，version；  
3.防重 Token 令牌；  
简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID 一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis 中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。如果不存在对应的 Key 或 Value 不匹配就返回重复执行的错误信息，这样来保证幂等操作。  
4.下游传递唯一序列号：  
所谓请求序列号，其实就是每次向服务端请求时候附带一个短时间内唯一不重复的序列号，该序列号可以是一个有序 ID，也可以是一个订单号，一般由下游生成，在调用上游服务端接口时附加该序列号和用于认证的 ID。  
当上游服务器收到请求信息后拿取该 序列号 和下游 认证ID 进行组合，形成用于操作 Redis 的 Key，然后到 Redis 中查询是否存在对应的 Key 的键值对，根据其结果：  
(1).如果存在，就说明已经对该下游的该序列号的请求进行了业务处理，这时可以直接响应重复请求的错误信息。  
(2).如果不存在，就以该 Key 作为 Redis 的键，以下游关键信息作为存储的值（例如下游商传递的一些业务逻辑信息），将该键值对存储到 Redis 中 ，然后再正常执行对应的业务逻辑即可。  

## 12.hashmap 原理，put 和 get，为什么是 8 转红黑树，红黑树节点添加过程，什么时候扩容，为什么是 0.75，扩容步骤，为什么分高低位，1.7 到 1.8 有什么优化，hash 算法做了哪些优化，头插法有什么问题，为什么线程不安全
为什么是 8 转红黑树：
链表长度超过 8 就转为红黑树的设计，更多的是为了防止用户自己实现了不好的哈希算法时导致链表过长，从而导致查询效率低，而此时转为红黑树更多的是一种保底策略，用来保证极端情况下查询的效率。  
通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。  

什么时候扩容：  
1.当HashMap中元素总个数达到阈值时就会扩容。注意是元素总个数，而不是数组占用个数。  
2比较复杂，当向HashMap中添加元素时，HashMap在jdk1.8之后引入了红黑树的概念，表示若桶中链表元素超过8时，会自动转化成红黑树；若桶中元素小于等于6时，树结构还原成链表形式。而如果当前数组的容量太小（小于64），则放弃转换，扩充数组。扩充数组！扩充数组！扩充数组！  

为什么是0.75：如果是0.5 ， 那么每次达到容量的一半就进行扩容，默认容量是16， 达到8就扩容成32，达到16就扩容成64， 最终使用空间和未使用空间的差值会逐渐增加，空间利用率低下。  如果是1，那意味着每次空间使用完毕才扩容，在一定程度上会增加put时候的时间。  

扩容步骤：1.扩容：创建一个新的Entry空数组，长度是原数组的2倍。2.ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。  

为什么分高低位：为了混合原始哈希码的高低位，以此来加大低位的随机性。而混合后的低位掺杂了高位的部份特征，这样高位的信息也被变相保留下来。  
```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

线程不安全：1.扩容造成死循环（头插法）；2.扩容造成数据丢失  

## 13.arraylist 原理，为什么数组加 transient，add 和 get 时间复杂度，扩容原理，和 linkedlist 区别，原理，分别在什么场景下使用，为什么
为什么数组加 transient：
ArrayList在序列化的时候会调用writeObject，直接将size和element写入ObjectOutputStream；反序列化时调用readObject，从ObjectInputStream获取size和element，再恢复到elementData。  
为什么不直接用elementData来序列化，而采用上诉的方式来实现序列化呢？原因在于elementData是一个缓存数组，它通常会预留一些容量，等容量不足时再扩充容量，那么有些空间可能就没有实际存储元素，采用上诉的方式来实现序列化时，就可以保证只序列化实际存储的那些元素，而不是整个数组，从而节省空间和时间。  

扩容原理：1、扩容，把原来的数组复制到另一个内存空间更大的数组中；2、添加元素，把新元素添加到扩容以后的数组中  

## 14.了解哪些并发工具类
CountDownLatch、ConcurrentHashMap

## 15.reentrantlock 的实现原理，加锁和释放锁的一个过程，aqs，公平和非公平，可重入，可中断怎么实现的
https://juejin.cn/post/6844903805683761165  
https://segmentfault.com/a/1190000014721183  



5. concurrenthashmap 原理，put，get，size，扩容，怎么保证线程安全的，1.7 和 1.8 的区别，为什么用 synchronized，分段锁有什么问题，hash 算法做了哪些优化

6. threadlocal 用过么，什么场景下使用的，原理，hash 冲突怎么办，扩容实现，会有线程安全问题么，内存泄漏产生原因，怎么解决

7. 垃圾收集算法，各有什么优缺点，gc roots 有哪些，什么情况下会发生 full gc

8. 了解哪些设计模式，工厂，策略，装饰者，桥接模式讲讲，单例模式会有什么问题

9. 对 spring aop 的理解，解决什么问题，实现原理，jdk 动态代理，cglib 区别，优缺点，怎么实现方法的调用的

10. mysql 中有一个索引(a,b,c)，有一条 sql，where a = 1 and b > 1 and c =1;可以用到索引么，为什么没用到，B+树的结构，为什么不用红黑树，B 树，一千万的数据大概多少次 io

11. mysql 聚簇索引，覆盖索引，底层结构，主键索引，没有主键怎么办，会自己生成主键为什么还要自定义主键，自动生成的主键有什么问题

12. redis 线程模型，单线程有什么优缺点，为什么单线程能保证高性能，什么情况下会出现阻塞，怎么解决

13. kafka 是怎么保证高可用性的，讲讲它的设计架构，为什么读写都在主分区，这样有什么优缺点

14. 了解 DDD 么，不是很了解

15. 你平时是怎么学习的

16. 项目介绍

1. 线程有哪些状态，等待状态怎么产生，死锁状态的变化过程，中止状态，interrupt()方法

2. 你怎么理解线程安全，哪些场景会产生线程安全问题，有什么解决办法

3. mysql 多事务执行会产生哪些问题，怎么解决这些问题

4. 分库分表做过么，怎么做到不停机扩容，双写数据丢失怎么办，跨库事务怎么解决

5. 你们用的 redis 集群么，扩容的过程，各个节点间怎么通信的

6. 对象一定分配在堆上么，JIT，分层编译，逃逸分析

7. es 的写入，查询过程，底层实现，为什么这么设计

8. es 集群，脑裂问题，怎么产生的，如何解决

9. while(true)里面一直 new thread().start()会有什么问题

10. socket 了解么，tcp 和 udp 的实现区别，不了解，用的不多

11. 设计一个秒杀系统能承受千万级并发，如果 redis 也扛不住了怎么办

12. 项目介绍

1. 讲讲你最熟悉的技术，jvm，mysql，redis，具体哪方面

2. new Object[100]对象大小，它的一个对象引用大小，对象头结构

3. mysql 主从复制，主从延时怎么解决

4. 怎么保证 redis 和 mysql 的一致性，redis 网络原因执行超时了会执行成功么，那不成功怎么保证数据一致性

5. redis 持久化过程，aof 持久化会出现阻塞么，一般什么情况下使用 rdb，aof

6. 线上有遇到大流量的情况么，产生了什么问题，为什么数据库 2000qps 就撑不住了，有想过原因么，你们当时怎么处理的

7. 限流怎么做，如果让你设计一个限流系统，怎么实现

8. dubbo 和 spring cloud 区别，具体区别，分别什么场景使用

9. 给了几个场景解决分布式事务问题

10. 项目介绍

11. 你觉得你们的业务对公司有什么实际价值，体现在哪，有什么数据指标么

1. 怎么理解用户态，内核态，为什么要分级别，有几种转换的方式，怎么转换的，转换失败怎么办

2. 怎么理解异常，它的作用是什么，你们工作中是怎么使用的

3. 你们用 redis 么，用来做什么，什么场景使用的，遇到过什么问题，怎么解决的

4. jvm 元空间内存结构，永久代有什么问题

5. 你平时开发中怎么解决问题，假如现在线上有一个告警，你的解决思路，过程

6. 你们为什么要用 mq，遇到过什么问题么，怎么就解决的

7. 你觉得和友商相比，你们的优势在哪

8. 聊天：炒股么，为什么买 B 站，天天用，看好他